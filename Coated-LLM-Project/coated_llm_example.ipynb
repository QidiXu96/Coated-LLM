{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6raTwolOggx9"
      },
      "outputs": [],
      "source": [
        "import openai_utils\n",
        "import warmup\n",
        "import pandas as pd\n",
        "import json\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQq5WDpnhLPb"
      },
      "source": [
        "#### Initialize OpenAI API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmU4kQCFhK0j"
      },
      "outputs": [],
      "source": [
        "api_key = \"your_openai_api\"  # Replace with your OpenAI API key\n",
        "openai_utils.initialize_openai(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk7Bsgaeic8I"
      },
      "outputs": [],
      "source": [
        "params = openai_utils.set_open_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-ibcf_EiiE8"
      },
      "source": [
        "#### Warm-up phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3qsBr9nhbf5",
        "outputId": "ce4f7d2f-47b9-49bb-9d46-5bb54eb3e948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HDF5 Output: embeddings.hdf5\n",
            "JSON Output: warm_up_CoT.json\n"
          ]
        }
      ],
      "source": [
        "# read demo training dataset\n",
        "training_data = pd.read_excel(\"/content/demo_data/demo_training_data.xlsx\")\n",
        "X_train = training_data[['Drug A', 'Drug B', 'Animal Model']]\n",
        "y_train = training_data['Efficacy']\n",
        "\n",
        "# process warmup phase\n",
        "output_hdf5_path, output_json_path = warmup.warmup(\n",
        "    X_train, y_train, params, openai_utils.client,\n",
        "    output_hdf5_path=\"embeddings.hdf5\",\n",
        "    pathway_dir=\"/content/demo_data/pathway\",\n",
        "    output_json_path=\"warm_up_CoT.json\"\n",
        ")\n",
        "\n",
        "print(f\"HDF5 Output: {output_hdf5_path}\")\n",
        "print(f\"JSON Output: {output_json_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPXSIUE1SZLb"
      },
      "source": [
        "entry_1, entry_3 are wrong predictions--> delete from training examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU2mCrHhSq6v"
      },
      "outputs": [],
      "source": [
        "# delete wrong predictions in json file\n",
        "with open('/content/warm_up_CoT.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "mismatched_entries = []\n",
        "\n",
        "for entry_id, entry in data.items():\n",
        "    if entry['predicted_answer'] != entry['real_answer']:\n",
        "        mismatched_entries.append(entry_id)\n",
        "\n",
        "for record in mismatched_entries:\n",
        "    if record in data:\n",
        "        del data[record]\n",
        "\n",
        "final_training_data = json.dumps(data)\n",
        "\n",
        "new_file_path = '/content/warm_up_CoT_final.json'\n",
        "\n",
        "with open(new_file_path, 'w') as new_file:\n",
        "    json.dump(data, new_file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYQGxsJvTSWe"
      },
      "outputs": [],
      "source": [
        "# delete wrong predictions in hdf5 file\n",
        "original_file_path = '/content/embeddings.hdf5'\n",
        "new_file_path = '/content/embeddings_final.hdf5'\n",
        "\n",
        "with h5py.File(original_file_path, 'r') as hdf_original:\n",
        "    with h5py.File(new_file_path, 'w') as hdf_new:\n",
        "        for entry in hdf_original:\n",
        "            if entry not in mismatched_entries:\n",
        "                hdf_original.copy(entry, hdf_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAyfhizRTsbk"
      },
      "source": [
        "#### Inference phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYPZECj7UUGT"
      },
      "source": [
        "dynamic few-shots learning examples + self-consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhlRtHyKXn81"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from inference import inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyWbGIWZYLdi"
      },
      "outputs": [],
      "source": [
        "embedding_hdf5_path = \"/content/embeddings_final.hdf5\"\n",
        "json_path = \"/content/warm_up_CoT_final.json\"\n",
        "pathway_dir = \"/content/demo_data/pathway\"\n",
        "test_data_path = \"/content/demo_data/demo_testing_data.xlsx\"\n",
        "output_dir = \"/content/test_results\" # create the folder\n",
        "\n",
        "X_test = pd.read_excel(test_data_path)\n",
        "\n",
        "with h5py.File(embedding_hdf5_path, 'r') as hdf5_file:\n",
        "    embeddings = [hdf5_file[name][:] for name in hdf5_file.keys()]\n",
        "    embedding_train = np.stack(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtR0jptFYeEU"
      },
      "outputs": [],
      "source": [
        "# perform self-consistency\n",
        "def run_multiple_inferences(X_test, iterations, n_neighbors, embedding_train, params, output_dir):\n",
        "    result_files = []\n",
        "    for iteration in range(1, iterations + 1):\n",
        "        result_file_path = inference(\n",
        "            X_test=X_test,\n",
        "            n=n_neighbors,\n",
        "            params=params,\n",
        "            embedding_train=embedding_train,\n",
        "            client=openai_utils.client,\n",
        "            iteration=iteration,\n",
        "            hdf5_path=embedding_hdf5_path,\n",
        "            json_path=json_path,\n",
        "            pathway_dir=pathway_dir,\n",
        "            output_dir=output_dir\n",
        "        )\n",
        "        result_files.append(result_file_path)\n",
        "        print(f\"Iteration {iteration} results saved to: {result_file_path}\")\n",
        "    return result_files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPrzAL7vYxak",
        "outputId": "0f4fbd68-766a-4d10-ca1f-742fe4fa0eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1 results saved to: /content/test_results/test_result_1.json\n",
            "Iteration 2 results saved to: /content/test_results/test_result_2.json\n",
            "Iteration 3 results saved to: /content/test_results/test_result_3.json\n"
          ]
        }
      ],
      "source": [
        "# Run inference for multiple iterations\n",
        "iterations = 3  # Number of iterations (iterations = 5 is better)\n",
        "n_neighbors = 2  # Number of neighbors for k-NN (n_neighbors = 5 is better)\n",
        "result_files = run_multiple_inferences(X_test, iterations, n_neighbors, embedding_train, params, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLcf5GbMaHaH"
      },
      "source": [
        "#### Revision phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaEoCrtKcQPE"
      },
      "outputs": [],
      "source": [
        "# Select CoT for reviewers\n",
        "excel_path = '/content/test_results/test_final.xlsx' # merge all previous test results and calculate majority vote\n",
        "df = pd.read_excel(excel_path)\n",
        "\n",
        "majority_answers = df.set_index('Entry ID')['Majority Vote'].to_dict()\n",
        "\n",
        "\n",
        "json_files = [\n",
        "    '/content/test_results/test_result_1.json',\n",
        "    '/content/test_results/test_result_2.json',\n",
        "    '/content/test_results/test_result_3.json'\n",
        "]\n",
        "\n",
        "select_chains = {}\n",
        "\n",
        "for json_file in json_files:\n",
        "    with open(json_file, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    for entry_id, entry_data in data.items():\n",
        "        question = entry_data['question']\n",
        "        chain_of_thoughts = entry_data['chain_of_thoughts']\n",
        "        predicted_answer = entry_data['predicted_answer']\n",
        "\n",
        "        # Check if the predicted answer matches the majority vote answer\n",
        "        if entry_id in majority_answers and predicted_answer == majority_answers[entry_id]:\n",
        "            # Check if the current chain of thoughts is the longest found so far\n",
        "            if entry_id not in select_chains or len(chain_of_thoughts) > len(select_chains[entry_id]['chain_of_thoughts']):\n",
        "                select_chains[entry_id] = {\n",
        "                    'question': question,\n",
        "                    'chain_of_thoughts': chain_of_thoughts,\n",
        "                    'predicted_answer': predicted_answer,\n",
        "                    'source_file': json_file  # Track the source file\n",
        "                }\n",
        "\n",
        "# Save the results to a JSON file\n",
        "output_path = '/content/test_results/select_chains.json'\n",
        "with open(output_path, 'w') as outfile:\n",
        "    json.dump(select_chains, outfile, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVBN2fMBaN_b"
      },
      "outputs": [],
      "source": [
        "import anthropic\n",
        "from pathlib import Path\n",
        "from reviewer import reviewer, process_reviewer_multiple_runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6QbTwRfaXzC",
        "outputId": "4a53bee1-7025-4b6d-f2d1-ccea0fa38091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 1 completed and saved to /content/feedback_results/feedbacks_1.json.\n",
            "All runs processed and saved.\n"
          ]
        }
      ],
      "source": [
        "anthropic_client = anthropic.Anthropic(\n",
        "    api_key = \"your_api\"\n",
        ")  # Replace with your api key\n",
        "\n",
        "# Define the input CoT JSON file and results directory\n",
        "CoT_json_file = \"/content/test_results/select_chains.json\"  # JSON file with chains of thought\n",
        "results_path = \"/content/feedback_results\"  # Create directory to save the feedback results\n",
        "\n",
        "# ToT Reviewer\n",
        "process_reviewer_multiple_runs(CoT_json_file, anthropic_client, results_path=results_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frXt1VzjeVlD"
      },
      "source": [
        "#### Moderator phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW9cjUBweZZ1",
        "outputId": "a0c9f36f-b1fa-415f-c30e-2fb65f0f8a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 1 completed and saved to /content/final_results/final_answer_with_feedback_1.json.\n",
            "Run 2 completed and saved to /content/final_results/final_answer_with_feedback_2.json.\n",
            "Run 3 completed and saved to /content/final_results/final_answer_with_feedback_3.json.\n",
            "All runs processed and saved.\n"
          ]
        }
      ],
      "source": [
        "from moderator import moderator, process_final_multiple_runs\n",
        "\n",
        "CoT_json_file = \"/content/test_results/select_chains.json\"\n",
        "feedback_path = \"/content/feedback_results/feedbacks_1.json\"\n",
        "results_path = \"/content/final_results\" # create folder to save final results\n",
        "\n",
        "process_final_multiple_runs(CoT_json_file, feedback_path, client, runs=3, results_path=results_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
