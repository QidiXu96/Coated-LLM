{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_open_params(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=2000,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "    \"\"\" set openai parameters\"\"\"\n",
    "\n",
    "    openai_params = {}    \n",
    "\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from openai api\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model = params['model'],\n",
    "        messages = messages,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = set_open_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsimilarexamples(drugA, drugB, animalmodel, n, embedding_train, client, hdf5_path=\"embeddings.hdf5\", json_path=\"warm_up_CoT.json\"):\n",
    "    test_question = f\"Decide if the combination of {drugA} and {drugB} is effective or not to treat {animalmodel} model in theory.\"\n",
    "    \n",
    "    # Generate embedding for the test question\n",
    "    embedding_response = client.embeddings.create(model=\"text-embedding-ada-002\", input=test_question)\n",
    "    test_question_embedding = embedding_response.data[0].embedding\n",
    "    X_test_reshape = np.array(test_question_embedding).reshape(1, -1)\n",
    "\n",
    "    # Fit the k-NN model on training embeddings\n",
    "    knn_model = NearestNeighbors(n_neighbors=n, metric='cosine')\n",
    "    knn_model.fit(embedding_train)\n",
    "    \n",
    "    distances, indices = knn_model.kneighbors(X_test_reshape)\n",
    "    most_similar_indices = indices.flatten()  # Get the indices of the most similar entries\n",
    "\n",
    "    # Fetch the most similar entries from the embedding HDF5 file\n",
    "    most_similar_keys = []\n",
    "    with h5py.File(hdf5_path, 'r') as file:\n",
    "        for index, key in enumerate(file.keys()):\n",
    "            if index in most_similar_indices:\n",
    "                most_similar_keys.append(key)\n",
    "                if len(most_similar_keys) == len(most_similar_indices):  # Stop when all keys are found\n",
    "                    break\n",
    "\n",
    "    # Fetch the most similar records' details (question and CoT) from the JSON file\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    most_similar_records_details = []\n",
    "    for key in most_similar_keys:\n",
    "        if key in data:\n",
    "            record = data[key]\n",
    "            question = record.get('question', 'No question available')\n",
    "            chain_of_thoughts = record.get('chain_of_thoughts', 'No chain of thoughts available')\n",
    "            most_similar_records_details.append({'question': question, 'chain_of_thoughts': chain_of_thoughts})\n",
    "\n",
    "    return test_question, most_similar_records_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(most_similar_records_details, test_question, infoA, infoB, params, client):\n",
    "    # create few-shot example\n",
    "    example_template = \"\"\"\n",
    "    Question: {question}\n",
    "    Reasons: {chain_of_thoughts}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \" \"\n",
    "\n",
    "    for record in most_similar_records_details:\n",
    "        prompt += example_template.format(question=record['question'], chain_of_thoughts=record['chain_of_thoughts'])\n",
    "        \n",
    "    prompt += '\\n\\n' + \"Background: \" + infoA + infoB + '\\n\\n'\n",
    "    prompt += test_question\n",
    "    prompt += \"Take a breath and work on this problem step by step. And conclude using the format 'Effective in theory: <Positive or Non-positive>.'\"\n",
    "\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert in therapy development for Alzheimer's disease and you are trying to decide if the combination of two drugs is effective or not to treat or slow the progression of Alzheimer's disease in theory.\\\n",
    "        Also, it is rare that combination of two drugs become efficacious and synergistic. \\\n",
    "        As a proficient neurobiologist, use your own knowledge and search for external information if necessary.\"\n",
    "    }, \n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }]\n",
    "    response = get_completion(params, messages)\n",
    "    CoT = response.choices[0].message.content\n",
    "        \n",
    "    return CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(X_test, n, params, embedding_train, client, iteration, pathway_dir=\"pathway\", output_dir=\"testing\"):\n",
    "    test_data = {}\n",
    "    file_path = Path(pathway_dir)\n",
    "\n",
    "    for i in X_test.index:\n",
    "        identifier = f\"entry_{i}\"\n",
    "\n",
    "        # Format pathway info\n",
    "        drugA_name = X_test.loc[i, 'Drug A']\n",
    "        drugB_name = X_test.loc[i, 'Drug B']\n",
    "\n",
    "        drugA_pathway = file_path / f\"{drugA_name}.csv\"\n",
    "        drugB_pathway = file_path / f\"{drugB_name}.csv\"\n",
    "\n",
    "        A_formatted_pathway_terms = \"\"\n",
    "        B_formatted_pathway_terms = \"\"\n",
    "\n",
    "        if drugA_pathway.exists():\n",
    "            A_pathway = pd.read_csv(drugA_pathway)\n",
    "            A_formatted_pathway_terms = ', '.join(A_pathway['Pathway'].tolist())\n",
    "\n",
    "        if drugB_pathway.exists():\n",
    "            B_pathway = pd.read_csv(drugB_pathway)\n",
    "            B_formatted_pathway_terms = ', '.join(B_pathway['Pathway'].tolist())\n",
    "\n",
    "        info_A = f\"{drugA_name} has several pathway information: {A_formatted_pathway_terms}\" if A_formatted_pathway_terms else \"\"\n",
    "        info_B = f\"{drugB_name} has several pathway information: {B_formatted_pathway_terms}\" if B_formatted_pathway_terms else \"\"\n",
    "\n",
    "        test_question, most_similar_records_details = getsimilarexamples(drugA_name, drugB_name, X_test.loc[i, 'Animal Model'], n, embedding_train, client)\n",
    "            \n",
    "        CoT = get_prompt(most_similar_records_details, test_question, info_A, info_B, params, client)\n",
    "            \n",
    "        test_data[identifier] = {\n",
    "                \"question\": test_question,\n",
    "                \"chain_of_thoughts\": CoT\n",
    "        }\n",
    "\n",
    "    result_file = Path(output_dir) / f\"test_result_{iteration}.json\"\n",
    "\n",
    "    with open(result_file, \"w\") as json_file:\n",
    "        json.dump(test_data, json_file, indent=4)\n",
    "\n",
    "    return str(result_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python-3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
